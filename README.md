# BIDIRECTIONAL-LSTM-FROM-SCRATCH

### A Bidirectional LSTM (biLSTM) is a sequence processing model that consists of two LSTMs: one taking the input in a forward direction, and the other in a backwards direction. The output layer can get information from past and future states simultaneously.


### <img src="https://user-images.githubusercontent.com/83499368/213111895-2f2b468c-0f17-4a71-896a-5fe510721fcd.png" width=60% height=50%>

### I have build Bidirectional LSTM(Long Short Term Memory) model from scratch by just using numpy and math in Python

## Bidirectional LSTM:
### -> forward propogation
### -> backward propagation

## Activation functions used: 
### -> sigmoid
### -> tanh
### -> softmax

### I have provided a pdf file explaning the working of the gates(input, output, forget) in the LSTM cell for both forward and backward propogation in LSTM

